{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "KDE bandwidth: 0.03476971577055476\n",
      "Fitting a KDE estimator\n",
      "Generating the alarm signal\n",
      "Optimizing the threshold\n",
      "Best threshold: 4.747474747474747\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Notebook setup\n",
    "# ============================================================\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from util import nab\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "data_folder = '../data/nab'\n",
    "file_name = 'realKnownCause/nyc_taxi.csv'\n",
    "data, labels, windows = nab.load_series(file_name, data_folder)\n",
    "\n",
    "# Train and validation end\n",
    "train_end = pd.to_datetime('2014-10-24 00:00:00')\n",
    "val_end = pd.to_datetime('2014-12-10 00:00:00')\n",
    "\n",
    "# Cost model parameters\n",
    "c_alrm = 1 # Cost of investigating a false alarm\n",
    "c_missed = 10 # Cost of missing an anomaly\n",
    "c_late = 5 # Cost for late detection\n",
    "\n",
    "# Compute the maximum over the training set\n",
    "trmax = data[data.index < train_end]['value'].max()\n",
    "# Normalize\n",
    "data['value'] = data['value'] / trmax\n",
    "# Separate the training data\n",
    "data_tr = data[data.index < train_end]\n",
    "\n",
    "# Compute the bandhwidth\n",
    "q1 = data_tr['value'].quantile(0.25)\n",
    "q3 = data_tr['value'].quantile(0.75)\n",
    "sigma = data_tr['value'].std()\n",
    "m =  len(data_tr)\n",
    "h = 0.9 * min(sigma, (q3-q1) / 1.34) * m**(-0.2)\n",
    "print(f'KDE bandwidth: {h}')\n",
    "\n",
    "# Build and fit a density estimator\n",
    "print('Fitting a KDE estimator')\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=h)\n",
    "kde.fit(data_tr)\n",
    "\n",
    "# Obtain the log probability density for all the data\n",
    "print('Generating the alarm signal')\n",
    "ldens = kde.score_samples(data)\n",
    "# Convert to a pandas series (add the time index)\n",
    "signal = pd.Series(index=data.index, data=-ldens)\n",
    "\n",
    "# Build a cost model\n",
    "cmodel = nab.ADSimpleCostModel(c_alrm, c_missed, c_late)\n",
    "\n",
    "# Separate train & validation set (for threshold optimization)\n",
    "signal_opt = signal[signal.index < val_end]\n",
    "labels_opt = labels[labels < val_end]\n",
    "windows_opt = windows[windows['end'] < val_end]\n",
    "thr_range = np.linspace(0, 10, 100)\n",
    "\n",
    "# Threshold optimization\n",
    "print('Optimizing the threshold')\n",
    "best_thr, best_cost = nab.opt_thr(signal_opt, labels_opt,\n",
    "                                  windows_opt,  cmodel, thr_range)\n",
    "print(f'Best threshold: {best_thr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Combining Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Combining Observations\n",
    "\n",
    "**An anomaly may be linked to a _sequence_ of observations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a406eec7dc844616b3063b346abb7a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zstart = windows.loc[4]['begin']\n",
    "zend = windows.loc[4]['end']\n",
    "zsignal = signal[(signal.index >= zstart) & (signal.index < zend)]\n",
    "nab.plot_series(zsignal, labels=labels.loc[4:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `loc` field in pandas addresses the index of a `DataFrame` or `Series`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Combining Observations\n",
    "\n",
    "**An anomaly may be linked to a _sequence_ of observations**\n",
    "\n",
    "It's a frequent case in real life:\n",
    "\n",
    "* Isolated outliers may be due to measurement noise\n",
    "  - e.g. faulty sensors, human mistakes\n",
    "* Real anomalies often _persist_ for a while\n",
    "\n",
    "**In this case it may be worth to _combine multiple probabilities_**\n",
    "\n",
    "* We will start by seeing a simple approach\n",
    "* ...Which makes the assumption that the observations are i.i.d.\n",
    "  - I.i.d.: Independent and Identically Distributed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Combining Observations\n",
    "\n",
    "* Let $\\bf x$ be a random variable corresponding to $n$ subsequent observations\n",
    "* We can formulate our new detection condition as follows:\n",
    "\n",
    "$$P({\\bf x}) \\leq \\theta^n$$\n",
    "\n",
    "Since we are assuming i.i.d. observations, we get:\n",
    "\n",
    "$$\\prod_{i=1}^n P(x_i) < \\theta^n$$\n",
    "\n",
    "With a log transformation:\n",
    "\n",
    "$$\\sum_{i=1}^n \\log P(x_i) < n \\log \\theta$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Combining Observations\n",
    "\n",
    "**Finally, we get:**\n",
    "\n",
    "$$\\frac{1}{n} \\sum_{i=1}^n \\log P(x_i) < \\theta$$\n",
    "\n",
    "Intuitively:\n",
    "\n",
    "* Considering multiple (independet, identical) observations\n",
    "* ...It's the same as _smoothing_ our signal using a _moving average_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Convolutions\n",
    "\n",
    "**We can implement the smoothing via a _convolution_:**\n",
    "\n",
    "Given a sequence $\\{x_i\\}_{i=1}^n$ and a sequence $\\{f_j\\}_{j=1}^m$ (a _filter_)\n",
    "\n",
    "* A convolution is an operation that \"slides\" the filter over the main series\n",
    "* ...And computes dot products to yield a third sequence $\\{y_k\\}_{k=m}^n$ s.t.:\n",
    "\n",
    "$$\n",
    "y_k = f \\cdot \\left(\\begin{array}{ccccc} x_{k-m} & x_{k-m+1} & x_{k-m+2} & \\ldots & x_k \\end{array}\\right)\n",
    "$$\n",
    "\n",
    "* I.e. the filter is applied to the first $m$ terms...\n",
    "* ...Then we move one time step forward and we repeat\n",
    "\n",
    "**Normally we need at least $m$ values before the first filter application**\n",
    "\n",
    "* Hence, the output series will be shorter than the input one\n",
    "* This is depicted by having the $y$ sequence start from index $m$\n",
    "* There are other ways (not discussed) to handle the series boundaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Convolutions\n",
    "\n",
    "**We want to compute a moving average**\n",
    "\n",
    "...Which is just the average of the last few values:\n",
    "\n",
    "* Let $m$ be the length of the time window for the moving average\n",
    "* Let us choose as filter: $\\left(\\frac{1}{m}, \\frac{1}{m}, \\ldots \\right)$\n",
    "\n",
    "**The convolution will compute an output sequence $\\{y_k\\}_{k=m}^m$, s.t.:**\n",
    "\n",
    "$$\n",
    "y_k = \\frac{1}{m} \\sum_{i=k-m}^k x_i\n",
    "$$\n",
    "\n",
    "This is exactly what we need!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Convolutions\n",
    "\n",
    "**First we build the filter:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "       0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "       0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "       0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "       0.04166667, 0.04166667, 0.04166667, 0.04166667])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_win_len = 24\n",
    "flt = np.ones(avg_win_len) / avg_win_len\n",
    "flt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The we apply the convolution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_signal = -np.convolve(ldens, flt, mode='valid')\n",
    "smooth_signal_idx = data.index[avg_win_len-1:]\n",
    "smooth_signal = pd.Series(index=smooth_signal_idx, data=smooth_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The convolution needs $n$ observations before it can be first applied\n",
    "* Hence, we need to _update the index_ for our smoothed signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Convolutions\n",
    "\n",
    "**In pandas, we can streamline this process via the `rolling` iterator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rolling [window=24,center=False,axis=0,method=single]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal.rolling(avg_win_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This will iterate over the series by groups of `avg_win_len` observations\n",
    "* Then we can compute the average with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2014-07-01 00:00:00         NaN\n",
       "2014-07-01 00:30:00         NaN\n",
       "2014-07-01 01:00:00         NaN\n",
       "2014-07-01 01:30:00         NaN\n",
       "2014-07-01 02:00:00         NaN\n",
       "                         ...   \n",
       "2015-01-31 21:30:00    0.104761\n",
       "2015-01-31 22:00:00    0.159036\n",
       "2015-01-31 22:30:00    0.232360\n",
       "2015-01-31 23:00:00    0.280827\n",
       "2015-01-31 23:30:00    0.307642\n",
       "Length: 10320, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal.rolling(avg_win_len).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Combining Observations\n",
    "\n",
    "**Let's plot the smoothed signal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0174f54139a449619c01d77d500f9fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nab.plot_series(smooth_signal, labels=labels, windows=windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some anomalies are now more evident!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Threshold Effect\n",
    "\n",
    "**We can now measure the effect of changing the threshold**\n",
    "\n",
    "First, we consider the \"idealized\" cost surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1892e693a5c4fa4bef2511272b00638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "smooth_thr_range = np.linspace(0.5, 2, 100)\n",
    "smooth_cost_range = [cmodel.cost(smooth_signal, labels, windows, thr)\n",
    "              for thr in smooth_thr_range]\n",
    "smooth_cost_range = pd.Series(index=smooth_thr_range, data=smooth_cost_range)\n",
    "nab.plot_series(smooth_cost_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Threshold Effect\n",
    "\n",
    "**It is worth to compare it with our orignial cost surface:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddbfca416196450ebf6022a81190617d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "thr_range = np.linspace(1, 10, 100)\n",
    "cost_range = [cmodel.cost(signal, labels, windows, thr) for thr in thr_range]\n",
    "cost_range = pd.Series(index=thr_range, data=cost_range)\n",
    "nab.plot_series(cost_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum is a bit lower with the smoothed signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Threshold Optimization\n",
    "\n",
    "**We can now optimize the threshold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.5303030303030303, corresponding cost: 15\n"
     ]
    }
   ],
   "source": [
    "smooth_signal_opt = smooth_signal[smooth_signal.index < val_end]\n",
    "smooth_best_thr, smooth_best_cost = nab.opt_thr(smooth_signal_opt, labels_opt,\n",
    "                                  windows_opt,  cmodel, smooth_thr_range)\n",
    "print(f'Best threshold: {smooth_best_thr}, corresponding cost: {smooth_best_cost}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Same cost as before on the trainining set\n",
    "* On the whole dataset, however:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on the whole dataset 37\n"
     ]
    }
   ],
   "source": [
    "smooth_ctst = cmodel.cost(smooth_signal, labels, windows, smooth_best_thr)\n",
    "print(f'Cost on the whole dataset {smooth_ctst}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The cost with  our original approach used to be 45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Some Considerations\n",
    "\n",
    "**It may worth combining multiple observations:**\n",
    "\n",
    "* If we notice that the data is noise\n",
    "* ...Or if we are interested in persistent anomalies\n",
    "\n",
    "**Combining multiple observations with an i.i.d. assumption...**\n",
    "\n",
    "* ...Is equivalent to smoothing with a moving average\n",
    "* ...And the other way round!\n",
    "* _Warning:_ the assumption may not be valid\n",
    "\n",
    "**The approach introduces an extra parameter (window length):**\n",
    "\n",
    "* In principle, we should optimize over that as well\n",
    "* We skipped that part for sake of simplicity"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "rise": {
   "center": false,
   "transition": "fade"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "4736a62c25c543a181b4da3d95164ca8": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.7.4",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_caf6518d738f483cb1b1b03d4891d3da",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Left button pans, Right button zooms\nx/y fixes axis, CTRL fixes aspect",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle\nx/y fixes axis, CTRL fixes aspect",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "7452c9c63c534b60baf159940cfcda99": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "caf6518d738f483cb1b1b03d4891d3da": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
